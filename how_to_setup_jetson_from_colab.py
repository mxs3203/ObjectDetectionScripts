# -*- coding: utf-8 -*-
"""how to setup Jetson

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YnKAUJgOfmsVz8Bpfi0Y0l1KGQN6_b1A
"""

# Jetson Nano - Jetpack 4.4

# for ubuntu updates
echo -e "Updating and upgrading Ubuntu..."
sudo apt-get update # Fetches the list of available updates
sudo apt-get upgrade # Strictly upgrades the current packages
echo -e "DONE with Updating and upgrading Ubuntu..."

# install tensorflow
echo -e "Installing Tensorflow dependency libraries"
sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran
sudo apt-get install python3-pip
sudo pip3 install -U pip
# here it can fail for Cython compile..., just try again or change make alias for python3
sudo pip3 install -U pip testresources setuptools numpy==1.16.1 future==0.17.1 mock==3.0.5 h5py==2.9.0 keras_preprocessing==1.0.5 keras_applications==1.0.8 gast==0.2.2 futures protobuf pybind11
# Check which python is running in terminal, if 2.7, make alias python=python3 in bashrc file

echo -e "Installing Tensorflow 2.2"
# TF-2.x
sudo pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v44 tensorflow==2.2.0+nv20.8

# ML CAN BE DONE USING TENSORFLOW OR PYTORCH(USING TF). FIRST PART IS ABOUT INSTALLING JETSON-DUSTY INFERENCE WHICH USES PYTORCH
# Jetson Dusty
echo -e "Installing dependency librires for building Jetson-Dusty library"
sudo apt-get install git cmake libpython3-dev python3-numpy

echo -e "Cloning GIT repository"
git clone --recursive https://github.com/dusty-nv/jetson-inference
cd jetson-inference
mkdir build
cd build
cmake ../
# tu se downloadaju modeli i py torch verzije i to se sve kompajla
# ako zelim downloadat modele ili drugu verziju pytorch 
./install-pytorch.sh
./download-models.sh
# ako ne zelim samo nastavljam dalje
cd jetson-inference/build          # omit if working directory is already build/ from above
make
sudo make install
sudo ldconfig

# training object detection

# from jetson-inference/python/training/detection/ssd

python train_ssd.py --model-dir=models/neutro --batch-size=4 --num-epochs=20 --data=/home/mateo/Desktop/Neutrophils2020_9_5_423Img --dataset-type=voc

# Install Label Image
sudo apt-get install pyqt5-dev-tools
sudo pip install lxml
git clone https://github.com/tzutalin/labelImg
cd labelImg
make qt5py3

# Install DARKNET
https://pjreddie.com/darknet/yolov2/

git clone https://github.com/pjreddie/darknet
cd darknet
make

wget https://pjreddie.com/media/files/yolov2.weights
./darknet detect cfg/yolov2.cfg yolov2.weights data/dog.jpg

# Unless you are on Jetson AGX Xavier, you should mount 4GB of swap space, as training uses up a lot of extra memory.

# Run these commands on Nano to create a swap file:

sudo fallocate -l 4G /mnt/4GB.swap
sudo mkswap /mnt/4GB.swap
sudo swapon /mnt/4GB.swap

Then add the following line to the end of /etc/fstab to make the change persistent:

/mnt/4GB.swap  none  swap  sw 0  0

# Make Annotation for pascal voc 
# Pascal Voc expects folder structure and if you make Annotations and JPEGImages folder this script will make 
# ImageSets folder for you with appropriate files in. Spliting test and train data

from pathlib import Path
import os
import random
import glob

trainval_percent = 0.8
train_percent = 1

xmlfilepath = 'Annotations'
txtsavepath = 'ImageSets/Main'
total_xml = glob.glob(os.path.join(xmlfilepath, '*.xml'))

Path(txtsavepath).mkdir(parents=True, exist_ok=True)

num=len(total_xml)
list=range(num)
tv=int(num*trainval_percent)
tr=int(tv*train_percent)
trainval= random.sample(list,tv)
train=random.sample(trainval,tr)
ftrainval = open('ImageSets/Main/trainval.txt', 'w')
ftest = open('ImageSets/Main/test.txt', 'w')
ftrain = open('ImageSets/Main/train.txt', 'w')
fval = open('ImageSets/Main/val.txt', 'w')

for i in list:
    name=os.path.basename(total_xml[i])[:-4]+'\n'
    if i in trainval:
        ftrainval.write(name)
        if i in train:
            ftrain.write(name)
        else:
            fval.write(name)
    else:
        ftest.write(name)

ftrainval.close()
ftrain.close()
fval.close()
ftest.close()

# Bash script for making structure for pytorch dusty training after downloading from roboflow train,tes,valid folders

mkdir Annotations
mkdir JPEGImages

mv test/*.xml Annotations/
mv train/*.xml Annotations/
mv valid/*.xml Annotations/
mv valid/*.jpg JPEGImages/
mv train/*.jpg JPEGImages/
mv test/*.jpg JPEGImages/

rm test
rm train
rm valid

# This script merges categories. Going through Annotations folder (input path) 
# and merging neutrophil_low and high as same class, also removing bg class

import xml.etree.ElementTree as ET
import sys
import glob
import os

from pathlib import Path


if (len(sys.argv) == 0):
    print("Please input hte annotation folder")
else:
    ANN_DIR = sys.argv[1]
    print(ANN_DIR)

for f in glob.glob(ANN_DIR + "*.xml"):

    tree = ET.parse(f)
    root = tree.getroot()
    for parent in root.findall('object'):
        for item in parent.findall('name'):
            if item.text == 'neutrophil_low':
                item.text = 'neutrophil'
            if item.text == 'neutrophil_high':
                item.text = 'neutrophil'
            if item.text == 'bg':
                root.remove(parent)

    Path(ANN_DIR + "../AfterAnnPreprocess/").mkdir(parents=True, exist_ok=True)
    tree.write(ANN_DIR + "../AfterAnnPreprocess/" + os.path.basename(f))

# HOW TO INSTALL TENSORFLOW MODELS AND TRAIN WITH TF INSTEAD OF PYTROCH LIKE IN DUSTY-JETSON


# FIND tf install dir with 
pip show tensorflow
cd tf_dir
# download models
git clone https://github.com/tensorflow/models.git

# install PROTOBUF and all dependencies
sudo apt-get install autoconf automake libtool curl make g++ unzip -y
cd protobuf
git submodule update --init --recursive
./autogen.sh
./configure --disable-shared
make
make check
sudo make install
sudo ldconfig

